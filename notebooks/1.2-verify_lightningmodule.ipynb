{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and Test our LightningModule\n",
    "\n",
    "This is where we will build our LightningModule and test it. The PyTorch Lightning Lightningmodule is a wrapper around a vanilla PyTorch nn.module that provides functionality for configuring optimizers, defining training and validation steps, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rootutils\n",
    "import os\n",
    "root = rootutils.setup_root(search_from=os.getcwd(), indicator=\".project-root\", dotenv=True, pythonpath=True, cwd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from monai import utils, transforms, networks, data, engines, losses, metrics, visualize, config, inferers, apps\n",
    "from monai.data import CacheDataset, DataLoader, list_data_collate, pad_list_data_collate, decollate_batch\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "# make sure you have numpy=1.26.0 bc of a bug between newer numpy and monai at the time of this writing. Will surely be solved by monai team in future.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import rootutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's paste our DataModule from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpleenDatamodule(L.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        batch_size: int = 2,\n",
    "        num_workers: int = 4,\n",
    "        pin_memory: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        # this below line allows to access init params with 'self.hparams' attribute\n",
    "        # also ensures init params will be stored in ckpt\n",
    "        self.save_hyperparameters(logger=False)\n",
    "        # self.batch_size = batch_size\n",
    "        # self.num_workers = num_workers\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download, split, etc...\n",
    "        # only called on 1 GPU/TPU in distributed\n",
    "        # we already downloaded our data so we will not do anything here\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # the stage is 'fit', 'validate', 'test', or 'predict'\n",
    "\n",
    "        # We first need to define the transforms that we will apply to the data\n",
    "        # Transforms may sound like they just augment the data, but they can also be used to preprocess the data, including loading the data and converting it to the correct format\n",
    "        self.train_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.LoadImaged(keys=[\"image\", \"label\"]),\n",
    "                transforms.EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "                transforms.Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "                transforms.Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
    "                transforms.ScaleIntensityRanged(keys=[\"image\"], a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True),\n",
    "                transforms.CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "                # transforms.EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "                transforms.RandCropByPosNegLabeld(keys=[\"image\", \"label\"], label_key=\"label\", spatial_size=(96, 96, 96), pos=1, neg=1, num_samples=4),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.val_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.LoadImaged(keys=[\"image\", \"label\"]),\n",
    "                transforms.EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "                transforms.Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "                transforms.Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
    "                transforms.ScaleIntensityRanged(keys=[\"image\"], a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True),\n",
    "                transforms.CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "                # transforms.EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.test_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.LoadImaged(keys=[\"image\", \"label\"]),\n",
    "                transforms.EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "                transforms.Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "                transforms.Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
    "                transforms.ScaleIntensityRanged(keys=[\"image\"], a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True),\n",
    "                transforms.CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "                # transforms.EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # make assignments here (val/train/test split)\n",
    "        # called on every process in DDP\n",
    "        # TODO: os.path.join() is not working???\n",
    "        # IMAGE_SRC = os.path.join(root,\"/data/Task09_Spleen/imagesTr\")\n",
    "        IMAGE_SRC = str(root) + \"/data/Task09_Spleen/imagesTr\"\n",
    "        # LABEL_SRC = os.path.join(root,\"/data/Task09_Spleen/labelsTr\")\n",
    "        LABEL_SRC = str(root) + \"/data/Task09_Spleen/labelsTr\"\n",
    "        SPLIT_NAME = \"MySplit\"\n",
    "        # this can be done by stage\n",
    "        # filenames = None\n",
    "        # if stage == \"fit\":\n",
    "        #     filenames = pd.read_csv(f\"/splits/{SPLIT_NAME}/train_{SPLIT_NAME}.csv\")\n",
    "        #     # Create a dictionary list of the image and label files labelled as 'image' and 'label'\n",
    "        #     self.train_files = [{\"image\": os.path.join(IMAGE_SRC, f\"{filename}.nii.gz\"), \"label\": os.path.join(LABEL_SRC, f\"{filename}.nii.gz\")} for filename in filenames]\n",
    "        #     self.train_ds = CacheDataset(data=self.train_files, transform=self.train_transforms, cache_rate=1.0, num_workers=self.num_workers)\n",
    "        # elif stage == \"validate\":\n",
    "        #     filenames = pd.read_csv(f\"/splits/{SPLIT_NAME}/val_{SPLIT_NAME}.csv\")\n",
    "        #     self.val_files = [{\"image\": os.path.join(IMAGE_SRC, f\"{filename}.nii.gz\"), \"label\": os.path.join(LABEL_SRC, f\"{filename}.nii.gz\")} for filename in filenames]\n",
    "        #     self.val_ds = CacheDataset(data=self.val_files, transform=self.val_transforms, cache_rate=1.0, num_workers=self.num_workers)\n",
    "        # elif stage == \"test\":\n",
    "        #     filenames = pd.read_csv(f\"/splits/{SPLIT_NAME}/test_{SPLIT_NAME}.csv\")\n",
    "        #     self.test_files = [{\"image\": os.path.join(IMAGE_SRC, f\"{filename}.nii.gz\"), \"label\": os.path.join(LABEL_SRC, f\"{filename}.nii.gz\")} for filename in filenames]\n",
    "        #     self.test_ds = CacheDataset(data=self.test_files, transform=self.test_transforms, cache_rate=1.0, num_workers=self.num_workers)\n",
    "        # else:\n",
    "        #     raise ValueError(f\"Stage {stage} not supported\")\n",
    "\n",
    "        # TODO: os.path.join() is not working for some reason\n",
    "        # train_csv = os.path.join(str(root),f\"/splits/{SPLIT_NAME}/train_{SPLIT_NAME}.csv\")\n",
    "        train_csv = f\"/splits/{SPLIT_NAME}/train_{SPLIT_NAME}.csv\"\n",
    "        # train_csv = os.path.join(str(root), train_csv)\n",
    "        train_csv = str(root) + train_csv\n",
    "        train_filenames = pd.read_csv(train_csv)\n",
    "        self.train_files = [{\"image\": os.path.join(IMAGE_SRC, row[\"image\"]), \"label\": os.path.join(LABEL_SRC, row[\"label\"])} for index, row in train_filenames.iterrows()]\n",
    "        # self.train_ds = CacheDataset(data=self.train_files, transform=self.train_transforms, cache_rate=1.0, num_workers=self.hparams.num_workers)\n",
    "        \n",
    "        val_csv = f\"/splits/{SPLIT_NAME}/val_{SPLIT_NAME}.csv\"\n",
    "        val_csv = str(root) + val_csv\n",
    "        val_filenames = pd.read_csv(val_csv)\n",
    "        self.val_files = [{\"image\": os.path.join(IMAGE_SRC, row[\"image\"]), \"label\": os.path.join(LABEL_SRC, row[\"label\"])} for index, row in val_filenames.iterrows()]\n",
    "        self.val_ds = CacheDataset(data=self.val_files, transform=self.val_transforms, cache_rate=1.0, num_workers=self.hparams.num_workers)\n",
    "        \n",
    "        test_csv = f\"/splits/{SPLIT_NAME}/test_{SPLIT_NAME}.csv\"\n",
    "        test_csv = str(root) + test_csv\n",
    "        test_filenames = pd.read_csv(test_csv)\n",
    "        self.test_files = [{\"image\": os.path.join(IMAGE_SRC, row[\"image\"]), \"label\": os.path.join(LABEL_SRC, row[\"label\"])} for index, row in test_filenames.iterrows()]\n",
    "        # self.test_ds = CacheDataset(data=self.test_files, transform=self.test_transforms, cache_rate=1.0, num_workers=self.hparams.num_workers)\n",
    "        \n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.train_ds,\n",
    "            batch_size=self.hparams.batch_size,         # we can use this nifty trick and access the hyperparameters directly since we used self.save_hyperparameters() up top\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=self.hparams.pin_memory,\n",
    "            collate_fn=list_data_collate,               # this collates our list of dictionaries into a dictionary of lists; not needed for if your dataset outputs something the default collate_fn can handle\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.val_ds,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=self.hparams.pin_memory,\n",
    "            collate_fn=pad_list_data_collate,\n",
    "            shuffle=False,\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.test_ds,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=self.hparams.pin_memory,\n",
    "            collate_fn=list_data_collate,\n",
    "            shuffle=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3259313981.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    class SpleenLightningModule(L.LightningModule):\u001b[0m\n\u001b[0m                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "class SpleenLightningModule(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        optimizer: torch.optim.Optimizer = None,\n",
    "        scheduler: torch.optim.lr_scheduler._LRScheduler = None,\n",
    "        loss: torch.nn.Module = None,\n",
    "        compile: bool = False,\n",
    "        lr: float = 1e-3,\n",
    "        ) -> None:\n",
    "        super().__init__()\n",
    "        self.model = networks.nets.UNet(\n",
    "            dimensions=3,\n",
    "            in_channels=1,\n",
    "            out_channels=2,\n",
    "            channels=(16, 32, 64, 128, 256),\n",
    "            strides=(2, 2, 2, 2),\n",
    "            num_res_units=2,\n",
    "            norm=Norm.BATCH,\n",
    "        )\n",
    "        self.loss = losses.DiceLoss(to_onehot_y=True, softmax=True)\n",
    "        self.metric = metrics.DiceMetric(include_background=False, reduction=\"mean\")\n",
    "        self.post_pred = inferers.Activation(inferers.Softmax())\n",
    "        self.post_label = inferers.Argmax()\n",
    "        self.val_dice = metrics.DiceMetric(include_background=False, reduction=\"mean\")\n",
    "        self.test_dice = metrics.DiceMetric(include_background=False, reduction=\"mean\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
