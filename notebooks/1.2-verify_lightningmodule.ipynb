{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and Test our LightningModule\n",
    "\n",
    "This is where we will build our LightningModule and test it. The PyTorch Lightning Lightningmodule is a wrapper around a vanilla PyTorch nn.module that provides functionality for configuring optimizers, defining training and validation steps, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rootutils\n",
    "import os\n",
    "root = rootutils.setup_root(search_from=os.getcwd(), indicator=\".project-root\", dotenv=True, pythonpath=True, cwd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from monai import utils, transforms, networks, data, engines, losses, metrics, visualize, config, inferers, apps\n",
    "from monai.data import CacheDataset, DataLoader, list_data_collate, pad_list_data_collate, decollate_batch\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "# make sure you have numpy=1.26.0 bc of a bug between newer numpy and monai at the time of this writing. Will surely be solved by monai team in future.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import rootutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's paste our DataModule from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpleenDatamodule(L.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        batch_size: int = 2,\n",
    "        num_workers: int = 4,\n",
    "        pin_memory: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        # this below line allows to access init params with 'self.hparams' attribute\n",
    "        # also ensures init params will be stored in ckpt\n",
    "        self.save_hyperparameters(logger=False)\n",
    "        # self.batch_size = batch_size\n",
    "        # self.num_workers = num_workers\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download, split, etc...\n",
    "        # only called on 1 GPU/TPU in distributed\n",
    "        # we already downloaded our data so we will not do anything here\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # the stage is 'fit', 'validate', 'test', or 'predict'\n",
    "\n",
    "        # We first need to define the transforms that we will apply to the data\n",
    "        # Transforms may sound like they just augment the data, but they can also be used to preprocess the data, including loading the data and converting it to the correct format\n",
    "        self.train_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.LoadImaged(keys=[\"image\", \"label\"]),\n",
    "                transforms.EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "                transforms.Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "                transforms.Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
    "                transforms.ScaleIntensityRanged(keys=[\"image\"], a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True),\n",
    "                transforms.CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "                # transforms.EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "                transforms.RandCropByPosNegLabeld(keys=[\"image\", \"label\"], label_key=\"label\", spatial_size=(96, 96, 96), pos=1, neg=1, num_samples=4),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.val_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.LoadImaged(keys=[\"image\", \"label\"]),\n",
    "                transforms.EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "                transforms.Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "                transforms.Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
    "                transforms.ScaleIntensityRanged(keys=[\"image\"], a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True),\n",
    "                transforms.CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "                # transforms.EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.test_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.LoadImaged(keys=[\"image\", \"label\"]),\n",
    "                transforms.EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "                transforms.Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "                transforms.Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
    "                transforms.ScaleIntensityRanged(keys=[\"image\"], a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True),\n",
    "                transforms.CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "                # transforms.EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # make assignments here (val/train/test split)\n",
    "        # called on every process in DDP\n",
    "        # TODO: os.path.join() is not working???\n",
    "        # IMAGE_SRC = os.path.join(root,\"/data/Task09_Spleen/imagesTr\")\n",
    "        IMAGE_SRC = str(root) + \"/data/Task09_Spleen/imagesTr\"\n",
    "        # LABEL_SRC = os.path.join(root,\"/data/Task09_Spleen/labelsTr\")\n",
    "        LABEL_SRC = str(root) + \"/data/Task09_Spleen/labelsTr\"\n",
    "        SPLIT_NAME = \"MySplit\"\n",
    "        # this can be done by stage\n",
    "        # filenames = None\n",
    "        # if stage == \"fit\":\n",
    "        #     filenames = pd.read_csv(f\"/splits/{SPLIT_NAME}/train_{SPLIT_NAME}.csv\")\n",
    "        #     # Create a dictionary list of the image and label files labelled as 'image' and 'label'\n",
    "        #     self.train_files = [{\"image\": os.path.join(IMAGE_SRC, f\"{filename}.nii.gz\"), \"label\": os.path.join(LABEL_SRC, f\"{filename}.nii.gz\")} for filename in filenames]\n",
    "        #     self.train_ds = CacheDataset(data=self.train_files, transform=self.train_transforms, cache_rate=1.0, num_workers=self.num_workers)\n",
    "        # elif stage == \"validate\":\n",
    "        #     filenames = pd.read_csv(f\"/splits/{SPLIT_NAME}/val_{SPLIT_NAME}.csv\")\n",
    "        #     self.val_files = [{\"image\": os.path.join(IMAGE_SRC, f\"{filename}.nii.gz\"), \"label\": os.path.join(LABEL_SRC, f\"{filename}.nii.gz\")} for filename in filenames]\n",
    "        #     self.val_ds = CacheDataset(data=self.val_files, transform=self.val_transforms, cache_rate=1.0, num_workers=self.num_workers)\n",
    "        # elif stage == \"test\":\n",
    "        #     filenames = pd.read_csv(f\"/splits/{SPLIT_NAME}/test_{SPLIT_NAME}.csv\")\n",
    "        #     self.test_files = [{\"image\": os.path.join(IMAGE_SRC, f\"{filename}.nii.gz\"), \"label\": os.path.join(LABEL_SRC, f\"{filename}.nii.gz\")} for filename in filenames]\n",
    "        #     self.test_ds = CacheDataset(data=self.test_files, transform=self.test_transforms, cache_rate=1.0, num_workers=self.num_workers)\n",
    "        # else:\n",
    "        #     raise ValueError(f\"Stage {stage} not supported\")\n",
    "\n",
    "        # TODO: os.path.join() is not working for some reason\n",
    "        # train_csv = os.path.join(str(root),f\"/splits/{SPLIT_NAME}/train_{SPLIT_NAME}.csv\")\n",
    "        train_csv = f\"/splits/{SPLIT_NAME}/train_{SPLIT_NAME}.csv\"\n",
    "        # train_csv = os.path.join(str(root), train_csv)\n",
    "        train_csv = str(root) + train_csv\n",
    "        train_filenames = pd.read_csv(train_csv)\n",
    "        self.train_files = [{\"image\": os.path.join(IMAGE_SRC, row[\"image\"]), \"label\": os.path.join(LABEL_SRC, row[\"label\"])} for index, row in train_filenames.iterrows()]\n",
    "        # Take only first few files of the dataset for testing\n",
    "        self.train_files = self.train_files[:2]     # take only the first 5 files for testing; COMMENT THIS LINE OUT FOR ACTUAL TRAINING\n",
    "        self.train_ds = CacheDataset(data=self.train_files, transform=self.train_transforms, cache_rate=1.0, num_workers=self.hparams.num_workers)\n",
    "        \n",
    "        val_csv = f\"/splits/{SPLIT_NAME}/val_{SPLIT_NAME}.csv\"\n",
    "        val_csv = str(root) + val_csv\n",
    "        val_filenames = pd.read_csv(val_csv)\n",
    "        self.val_files = [{\"image\": os.path.join(IMAGE_SRC, row[\"image\"]), \"label\": os.path.join(LABEL_SRC, row[\"label\"])} for index, row in val_filenames.iterrows()]\n",
    "        self.val_files = self.val_files[:2]     # take only the first 5 files for testing; COMMENT THIS LINE OUT FOR ACTUAL TRAINING\n",
    "        self.val_ds = CacheDataset(data=self.val_files, transform=self.val_transforms, cache_rate=1.0, num_workers=self.hparams.num_workers)\n",
    "        \n",
    "        test_csv = f\"/splits/{SPLIT_NAME}/test_{SPLIT_NAME}.csv\"\n",
    "        test_csv = str(root) + test_csv\n",
    "        test_filenames = pd.read_csv(test_csv)\n",
    "        self.test_files = [{\"image\": os.path.join(IMAGE_SRC, row[\"image\"]), \"label\": os.path.join(LABEL_SRC, row[\"label\"])} for index, row in test_filenames.iterrows()]\n",
    "        self.test_files = self.test_files[:2]     # take only the first 5 files for testing; COMMENT THIS LINE OUT FOR ACTUAL TRAINING\n",
    "        self.test_ds = CacheDataset(data=self.test_files, transform=self.test_transforms, cache_rate=1.0, num_workers=self.hparams.num_workers)\n",
    "        \n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.train_ds,\n",
    "            batch_size=self.hparams.batch_size,         # we can use this nifty trick and access the hyperparameters directly since we used self.save_hyperparameters() up top\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=self.hparams.pin_memory,\n",
    "            collate_fn=list_data_collate,               # this collates our list of dictionaries into a dictionary of lists; not needed for if your dataset outputs something the default collate_fn can handle\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.val_ds,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=self.hparams.pin_memory,\n",
    "            collate_fn=pad_list_data_collate,\n",
    "            shuffle=False,\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.test_ds,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=self.hparams.pin_memory,\n",
    "            collate_fn=list_data_collate,\n",
    "            shuffle=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpleenLightningModule(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        optimizer: torch.optim.Optimizer = None,\n",
    "        scheduler: torch.optim.lr_scheduler = None,\n",
    "        loss_fn: torch.nn.Module = None,\n",
    "        compile: bool = False,\n",
    "        lr: float = 1e-3,\n",
    "        ) -> None:\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = networks.nets.UNet(\n",
    "            spatial_dims=3,\n",
    "            in_channels=1,\n",
    "            out_channels=2,\n",
    "            channels=(16, 32, 64, 128, 256),\n",
    "            strides=(2, 2, 2, 2),\n",
    "            num_res_units=2,\n",
    "            norm=Norm.BATCH,\n",
    "        )\n",
    "\n",
    "        self.loss_fn = losses.DiceLoss(to_onehot_y=True, softmax=True)\n",
    "        self.metric = metrics.DiceMetric(include_background=False, reduction=\"mean\")\n",
    "\n",
    "        # self.post_pred = transforms.Compose([transforms.EnsureType(\"tensor\", device=\"cpu\"), transforms.AsDiscrete(armax=True, to_onehot=2)])\n",
    "        self.post_pred = transforms.Compose([transforms.EnsureType(\"tensor\", device=\"cpu\"), transforms.AsDiscrete(armax=True)])\n",
    "        # The post_pred transform is giving me an error that \"labels should have a channel with length equal to on\" so I think it needs to output a single channel image\n",
    "        # I think the issue is that the output of the model is a 2 channel image, but the labels are a single channel image\n",
    "        # I can fix this by adding a channel dimension to the labels\n",
    "        self.post_label = transforms.Compose([transforms.EnsureType(\"tensor\", device=\"cpu\"), transforms.AsDiscrete(to_onehot=2)])\n",
    "\n",
    "        self.best_val_dice = 0\n",
    "        self.best_val_epoch = 0\n",
    "        self.validation_step_outputs = []\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.hparams.lr)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch[\"image\"], batch[\"label\"]\n",
    "        outputs = self(images)\n",
    "        loss = self.loss_fn(outputs, labels)\n",
    "        self.log(\"train/loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch[\"image\"], batch[\"label\"]\n",
    "        roi_size = (160, 160, 160)\n",
    "        sw_batch_size = 4\n",
    "        # We should use sliding window inference not because it reduces memory usage (that's not a problem on HPG) but\n",
    "        # rather because it apparently can increase accuracy by multiple percentage points for things like Dice.\n",
    "        # We totally could just have outputs = self.forward(images)\n",
    "        # However, sliding window inference is apparently more accurate for things like Dice.\n",
    "        outputs = inferers.sliding_window_inference(images, roi_size, sw_batch_size, self.forward)\n",
    "        loss = self.loss_fn(outputs, labels)\n",
    "        print(\"output shape is:\")\n",
    "        print(outputs.shape)\n",
    "        print(\"label shape is:\")\n",
    "        print(labels.shape)\n",
    "        print(\"decollated batch shape is:\")\n",
    "        print(decollate_batch(outputs)[0].shape)\n",
    "        outputs = [self.post_pred(i) for i in decollate_batch(outputs)]\n",
    "        labels = [self.post_label(i) for i in decollate_batch(labels)]\n",
    "        dice = self.metric(y_pred=outputs, y=labels)\n",
    "        self.log(\"val/loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val/dice\", dice.mean(), on_step=False, on_epoch=True, prog_bar=True)\n",
    "        d = {\"val_loss\": loss, \"val_number\": len(outputs)}\n",
    "        self.validation_step_outputs.append(d)\n",
    "        return d\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        val_loss, num_items = 0, 0\n",
    "        for output in self.validation_step_outputs:\n",
    "            val_loss += output[\"val_loss\"].sum().item()\n",
    "            num_items += output[\"val_number\"]\n",
    "        mean_val_dice = self.metric.aggregate().item()\n",
    "        self.metric.reset()\n",
    "        mean_val_loss = torch.tensor(val_loss / num_items)\n",
    "        self.log(\"val/mean_dice\", mean_val_dice, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val/mean_loss\", mean_val_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        if mean_val_dice > self.best_val_dice:\n",
    "            self.best_val_dice = mean_val_dice\n",
    "            self.best_val_epoch = self.current_epoch\n",
    "        print(\n",
    "            f\"current epoch: {self.current_epoch} \"\n",
    "            f\"current mean dice: {mean_val_dice:.4f}\"\n",
    "            f\"\\nbest mean dice: {self.best_val_dice:.4f} \"\n",
    "            f\"at epoch: {self.best_val_epoch}\"\n",
    "        )\n",
    "        self.validation_step_outputs.clear()  # free memory\n",
    "        return\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        images, labels = batch[\"image\"], batch[\"label\"]\n",
    "        roi_size = (160, 160, 160)\n",
    "        sw_batch_size = 4\n",
    "        outputs = inferers.sliding_window_inference(images, roi_size, sw_batch_size, self.forward)\n",
    "        loss = self.loss_fn(outputs, labels)\n",
    "        outputs = [self.post_pred(i) for i in decollate_batch(outputs)]\n",
    "        labels = [self.post_label(i) for i in decollate_batch(labels)]\n",
    "        dice = self.metric(y_pred=outputs, y=labels)\n",
    "        self.log(\"test/loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test/dice\", dice, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/sasank.desaraju/.conda/envs/monai/lib/python3. ...\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "Loading dataset: 100%|██████████| 2/2 [00:06<00:00,  3.31s/it]\n",
      "Loading dataset: 100%|██████████| 2/2 [00:06<00:00,  3.15s/it]\n",
      "Loading dataset: 100%|██████████| 2/2 [00:06<00:00,  3.43s/it]\n",
      "\n",
      "  | Name    | Type     | Params | Mode \n",
      "---------------------------------------------\n",
      "0 | model   | UNet     | 4.8 M  | train\n",
      "1 | loss_fn | DiceLoss | 0      | train\n",
      "---------------------------------------------\n",
      "4.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.8 M     Total params\n",
      "19.236    Total estimated model params size (MB)\n",
      "This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:13<00:00,  0.08it/s]output shape is:\n",
      "torch.Size([2, 2, 272, 264, 223])\n",
      "label shape is:\n",
      "torch.Size([2, 1, 272, 264, 223])\n",
      "decollated batch shape is:\n",
      "torch.Size([2, 272, 264, 223])\n",
      "current epoch: 0 current mean dice: 0.0054\n",
      "best mean dice: 0.0054 at epoch: 0\n",
      "Epoch 0: 100%|██████████| 1/1 [00:42<00:00,  0.02it/s, val/loss=0.657, val/dice=0.00536, val/mean_dice=0.00536, val/mean_loss=0.329, train/loss=0.652]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:42<00:00,  0.02it/s, val/loss=0.657, val/dice=0.00536, val/mean_dice=0.00536, val/mean_loss=0.329, train/loss=0.652]\n"
     ]
    }
   ],
   "source": [
    "# Run quick \"training\" run with fast_dev_run=True so that it just runs one batch of train and val\n",
    "\n",
    "datamodule = SpleenDatamodule(batch_size=2, num_workers=4, pin_memory=False)\n",
    "model = SpleenLightningModule(lr=1e-3)\n",
    "\n",
    "logger = L.pytorch.loggers.csv_logs.CSVLogger(save_dir=\"logs\", name=\"spleen_dev\")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    fast_dev_run=True,\n",
    "    max_epochs=1,\n",
    "    devices=\"auto\",\n",
    "    accelerator=\"auto\",\n",
    "    logger=logger,\n",
    "    log_every_n_steps=1,\n",
    ")\n",
    "\n",
    "trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we are ready to incorporate the DataModule and LightningModule into .py files in the `src` directory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
